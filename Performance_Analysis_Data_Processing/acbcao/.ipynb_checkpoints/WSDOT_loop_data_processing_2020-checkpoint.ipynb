{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop data handling and processing\n",
    "\n",
    "### *the code below helps calculate the daily, hourly average traffic volume based on the given data (collected from WSDOT loop: https://tracflow.wsdot.wa.gov/contourdata/brainscan)*\n",
    "\n",
    "## We separate the code into three parts for sharing\n",
    "### 1. Needed packages \n",
    "### 2. Utility functions\n",
    "### 3. Examples  da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import *\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions\n",
    "After you download the data from WSDOT loop, you will receive some zip files the function below helps you unzip the file, check if the loop encounter with a large number of missing data issues based on your interested date period, and keep the .xlsx file only.\n",
    "Note: The volume sheet under the excel file should look like below:\n",
    "column should follow: year-month-day hour:minute:second,\n",
    "row (here we use hourly average) should follow: hour:minute:second\n",
    "\n",
    "- input: \n",
    "    - filepath: file path you store the zip file \n",
    "    - date1: start date \n",
    "    - date2: end date\n",
    "- output: \n",
    "    - .xlsx files from the zip file which have data based on your given date period\n",
    "    - Calculated daily, hourly traffic volume and its corresponding plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the detailed data format is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-01-05</th>\n",
       "      <th>2019-01-06</th>\n",
       "      <th>2019-01-07</th>\n",
       "      <th>2019-01-08</th>\n",
       "      <th>2019-01-09</th>\n",
       "      <th>2019-01-10</th>\n",
       "      <th>2019-01-11</th>\n",
       "      <th>2019-01-12</th>\n",
       "      <th>2019-01-13</th>\n",
       "      <th>2019-01-14</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-03-22</th>\n",
       "      <th>2019-03-23</th>\n",
       "      <th>2019-03-24</th>\n",
       "      <th>2019-03-25</th>\n",
       "      <th>2019-03-26</th>\n",
       "      <th>2019-03-27</th>\n",
       "      <th>2019-03-28</th>\n",
       "      <th>2019-03-29</th>\n",
       "      <th>2019-03-30</th>\n",
       "      <th>2019-03-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00:00:00</th>\n",
       "      <td>1309</td>\n",
       "      <td>1481</td>\n",
       "      <td>1180</td>\n",
       "      <td>1058</td>\n",
       "      <td>881</td>\n",
       "      <td>852</td>\n",
       "      <td>912</td>\n",
       "      <td>1509</td>\n",
       "      <td>1560</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1076</td>\n",
       "      <td>-1</td>\n",
       "      <td>1640</td>\n",
       "      <td>1405</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1095</td>\n",
       "      <td>1038</td>\n",
       "      <td>1159</td>\n",
       "      <td>1596</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01:00:00</th>\n",
       "      <td>868</td>\n",
       "      <td>948</td>\n",
       "      <td>741</td>\n",
       "      <td>727</td>\n",
       "      <td>645</td>\n",
       "      <td>618</td>\n",
       "      <td>647</td>\n",
       "      <td>945</td>\n",
       "      <td>949</td>\n",
       "      <td>615.0</td>\n",
       "      <td>...</td>\n",
       "      <td>738</td>\n",
       "      <td>-1</td>\n",
       "      <td>1018</td>\n",
       "      <td>618</td>\n",
       "      <td>681.0</td>\n",
       "      <td>679</td>\n",
       "      <td>750</td>\n",
       "      <td>688</td>\n",
       "      <td>945</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02:00:00</th>\n",
       "      <td>680</td>\n",
       "      <td>278</td>\n",
       "      <td>595</td>\n",
       "      <td>617</td>\n",
       "      <td>619</td>\n",
       "      <td>545</td>\n",
       "      <td>669</td>\n",
       "      <td>756</td>\n",
       "      <td>784</td>\n",
       "      <td>580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>717</td>\n",
       "      <td>-1</td>\n",
       "      <td>782</td>\n",
       "      <td>671</td>\n",
       "      <td>672.0</td>\n",
       "      <td>626</td>\n",
       "      <td>677</td>\n",
       "      <td>726</td>\n",
       "      <td>766</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03:00:00</th>\n",
       "      <td>700</td>\n",
       "      <td>-5</td>\n",
       "      <td>1083</td>\n",
       "      <td>1081</td>\n",
       "      <td>1067</td>\n",
       "      <td>1127</td>\n",
       "      <td>1149</td>\n",
       "      <td>809</td>\n",
       "      <td>595</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1353</td>\n",
       "      <td>-1</td>\n",
       "      <td>642</td>\n",
       "      <td>1245</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>1302</td>\n",
       "      <td>1241</td>\n",
       "      <td>1255</td>\n",
       "      <td>768</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04:00:00</th>\n",
       "      <td>1224</td>\n",
       "      <td>-5</td>\n",
       "      <td>3061</td>\n",
       "      <td>3096</td>\n",
       "      <td>3109</td>\n",
       "      <td>3116</td>\n",
       "      <td>3280</td>\n",
       "      <td>1431</td>\n",
       "      <td>916</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3436</td>\n",
       "      <td>-1</td>\n",
       "      <td>911</td>\n",
       "      <td>3523</td>\n",
       "      <td>3423.0</td>\n",
       "      <td>3494</td>\n",
       "      <td>3460</td>\n",
       "      <td>3337</td>\n",
       "      <td>1256</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2019-01-05  2019-01-06  2019-01-07  2019-01-08  2019-01-09  \\\n",
       "00:00:00        1309        1481        1180        1058         881   \n",
       "01:00:00         868         948         741         727         645   \n",
       "02:00:00         680         278         595         617         619   \n",
       "03:00:00         700          -5        1083        1081        1067   \n",
       "04:00:00        1224          -5        3061        3096        3109   \n",
       "\n",
       "          2019-01-10  2019-01-11  2019-01-12  2019-01-13  2019-01-14  ...  \\\n",
       "00:00:00         852         912        1509        1560      1018.0  ...   \n",
       "01:00:00         618         647         945         949       615.0  ...   \n",
       "02:00:00         545         669         756         784       580.0  ...   \n",
       "03:00:00        1127        1149         809         595      1170.0  ...   \n",
       "04:00:00        3116        3280        1431         916      3721.0  ...   \n",
       "\n",
       "          2019-03-22  2019-03-23  2019-03-24  2019-03-25  2019-03-26  \\\n",
       "00:00:00        1076          -1        1640        1405      1052.0   \n",
       "01:00:00         738          -1        1018         618       681.0   \n",
       "02:00:00         717          -1         782         671       672.0   \n",
       "03:00:00        1353          -1         642        1245      1268.0   \n",
       "04:00:00        3436          -1         911        3523      3423.0   \n",
       "\n",
       "          2019-03-27  2019-03-28  2019-03-29  2019-03-30  2019-03-31  \n",
       "00:00:00        1095        1038        1159        1596        1644  \n",
       "01:00:00         679         750         688         945        1017  \n",
       "02:00:00         626         677         726         766         759  \n",
       "03:00:00        1302        1241        1255         768         643  \n",
       "04:00:00        3494        3460        3337        1256         914  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_excel(\"../acbcao/005es16237_MN__ MTWThFSaS Jan-Mar 2019 _60m.xlsx\", sheet_name=\"Volume\",index_col=0)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file and process the data\n",
    "def raw_data_process(filepath, date1, date2):\n",
    "    # get all the files under the given path\n",
    "    folders = os.listdir(filepath)\n",
    "    # check the zip file and unzip them all\n",
    "    for i in folders:\n",
    "        if i[-3:] == 'zip':\n",
    "            zip = ZipFile(filepath+i)\n",
    "            zip.extractall(path=filepath)\n",
    "\n",
    "    files = os.listdir(filepath)\n",
    "    # get current xlsx file and remove the .png file  \n",
    "    dtfiles = []\n",
    "    index = 0\n",
    "    for i in files:\n",
    "        if i[-4:] == 'xlsx':\n",
    "            dtfiles.append(filepath+i)\n",
    "        if i[-3:] == 'png':\n",
    "            os.remove(filepath+i)\n",
    "        # if other files detected, print a caution, the other files which not directly\n",
    "        # from the folder may cause some error for the other function\n",
    "        # set up an index to detect such situation to avoid repeated print\n",
    "        elif index == 0 and i[:-4]!='xlsx' and i[-3:]!='png':\n",
    "                print('Caution: there are other files detected except the zipped file in the given folder')\n",
    "                print('Warning: other files may cause error for other functions')\n",
    "                index = index + 1\n",
    "                      \n",
    "            \n",
    "    # check data and delete .xlsx fle with missing data only with the period you are interested\n",
    "    for excel in dtfiles:\n",
    "        dt = pd.read_excel(excel, sheet_name='Volume', index_col=0)\n",
    "        col =  list(dt.columns)\n",
    "        a = 0 \n",
    "        for coln in col:\n",
    "            try:\n",
    "                if datetime.strptime(str(coln),'%Y-%m-%d %H:%M:%S') >= date1 and datetime.strptime(str(coln),'%Y-%m-%d %H:%M:%S') <= date2:\n",
    "                    a = a+sum(dt[coln])\n",
    "            except:\n",
    "                print('Colume format error, check if colume name follows date format: year-month-day hour:minute:second')\n",
    "        if a < 0:\n",
    "            os.remove(excel)\n",
    "\n",
    "# data processing\n",
    "# here we tide the data into ditrect format\n",
    "# the output looks like {loopid:{time period:{datetime:[vol]}}} where vol is ordered by hour\n",
    "# e.g., {'005es16186_MN':'BC':datetime(2019,1,5,0,0):[100, 200, 300,...]}\n",
    "# create the dict followed by the format\n",
    "def makeloopvol(periodlst, pathfile):  \n",
    "    # get current pathfile\n",
    "    dtfiles = get_datafile(pathfile)\n",
    "    loop_vol = {}\n",
    "    for excel in dtfiles:\n",
    "        # get the index of loop id from the .xlsx path\n",
    "        # the excel name should look similar as th eformat below:\n",
    "        # \"005es16186_MN__ MTWThFSaS Jan-Mar 2019 _60m.xlsx\"\n",
    "        # the loop id looks like 005es16186_MN where 005 is the route, 16186 is the milepost for the loops\n",
    "        # MN is the direction, in this example, MN stands form North bound\n",
    "        # here we call getloopidindex to locate the loopid based on its excel path\n",
    "        index1,index2 = getloopidindex(excel)\n",
    "        loop_vol[excel[index1:index2]] = {}\n",
    "        for period in periodlst:\n",
    "            loop_vol[excel[index1:index2]][period] = {}\n",
    "    return(loop_vol)\n",
    "\n",
    "def getloopidindex(excel_path):\n",
    "    direction = ['MN_', 'MS_', 'MW_', 'ME_']\n",
    "    for direct in direction:\n",
    "        if direct in excel_path:\n",
    "            index = excel_path.index(direct[1:])\n",
    "            # return the location of the loopid based on the excel path string\n",
    "            # 12 is the length of the loopid, e.g., 005es16186_MN\n",
    "            return(index-12, index+1)\n",
    "            break  \n",
    "\n",
    "# get current .xlsx in the folder\n",
    "def get_datafile(pathfile):\n",
    "    files = os.listdir(pathfile)\n",
    "    dtfiles = []\n",
    "    for i in files:\n",
    "        if i[-4:] == 'xlsx' and i[0]!='~':\n",
    "            dtfiles.append(pathfile+i)\n",
    "    return(dtfiles)\n",
    "\n",
    "# if negative value is found for volume (regarding as missing value), convert them to zero\n",
    "def convert_negative_val(lst):\n",
    "    a = 0\n",
    "    tup = np.nonzero(lst)\n",
    "    for i in tup:\n",
    "        cklst = i\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] < 0:\n",
    "            lst[i] = 0\n",
    "    return(lst)\n",
    "\n",
    "# get loop volume\n",
    "def get_loop(t1, t2, dt, day, period, loopid, loop_vol, date):                    \n",
    "    if date >= t1 and date <= t2:\n",
    "        volst = convert_negative_val(list(dt[day]))\n",
    "        if volst != None:\n",
    "            loop_vol[loopid][period][date] = []\n",
    "            loop_vol[loopid][period][date] = volst\n",
    "    return(loop_vol)\n",
    "            \n",
    "def excel_processing(pathfile, periodlst, time_bond, loop_vol):\n",
    "    dtfiles = get_datafile(pathfile)\n",
    "    for excel in dtfiles:\n",
    "        dt = pd.read_excel(excel, sheet_name='Volume', index_col=0)\n",
    "        # get the index of loop id from the .xlsx path\n",
    "        index1,index2 = getloopidindex(excel)\n",
    "        loopid = excel[index1:index2]\n",
    "        daylst = list(dt.columns)\n",
    "        hourlst = list(dt.index)\n",
    "        # check data availability during befor closure period\n",
    "        for day in daylst:\n",
    "            date = datetime.strptime(str(day),'%Y-%m-%d %H:%M:%S')\n",
    "            loop_vol = get_loop(time_bond[0], time_bond[1], dt, day, periodlst[0], loopid, loop_vol, date)\n",
    "            loop_vol = get_loop(time_bond[2], time_bond[3], dt, day, periodlst[1], loopid, loop_vol, date)\n",
    "            loop_vol = get_loop(time_bond[4], time_bond[5], dt, day, periodlst[2], loopid, loop_vol, date)\n",
    "    return(loop_vol)\n",
    "\n",
    "#get latitude and longitude for each loop\n",
    "def get_loop_location(loopvol, pathfile):\n",
    "    dtfiles = get_datafile(pathfile)\n",
    "    # create a loc direct to stire lat, lon for each loop id\n",
    "    loc = {}\n",
    "    for i in loopvol:\n",
    "        loc[i] = []\n",
    "    for j in dtfiles:\n",
    "        dt = pd.read_excel(j, sheet_name='Metadata')\n",
    "        index1,index2 = getloopidindex(j)\n",
    "        loc[j[index1:index2]] = list(dt.iloc[0][1:])\n",
    "    return(loc)\n",
    "\n",
    "# calculate the value\n",
    "# calculate daily average by loop within a week (by day, mor_peak, eve_peak)\n",
    "# calculate daily average (by Sat, Sun, Mon,...) by day\n",
    "def CalVol(loopvoldict, t1, t2, d1, d2):\n",
    "    wkavg_loop = {}\n",
    "    davg_loop = {} \n",
    "    for lpid in loopvoldict:\n",
    "        # create dict to store daily and weekly average\n",
    "        wkavg_loop[lpid] = {}\n",
    "        davg_loop[lpid] = {}\n",
    "        pdlst = list(loopvoldict[lpid].keys())\n",
    "        for pd in pdlst:\n",
    "            wkavg_loop[lpid][pd] = 0\n",
    "            davg_loop[lpid][pd] = {}\n",
    "            date_time = list(loopvoldict[lpid][pd].keys())\n",
    "            # call the CalWeekAvg function to calculate the weekday traffic volume average for each loop id\n",
    "            wkavg_loop[lpid][pd] = CalWeekAvg(loopvoldict, date_time, lpid, pd, t1, t2, d1, d2)\n",
    "            # call the CaldailyAvg function to calculate the daily traffic volume average for each loop id\n",
    "            davg_loop[lpid][pd] = CaldailyAvg(loopvoldict, date_time, lpid, pd, t1, t2, d1, d2)\n",
    "    return(wkavg_loop, davg_loop)\n",
    "\n",
    "def CalWeekAvg(loopdict, datetime, loopid, period, t1, t2, d1, d2):\n",
    "    vol = 0\n",
    "    n = 0 \n",
    "    for day in datetime:\n",
    "        if day.weekday() >= d1 and day.weekday() <= d2:\n",
    "            loopvol = loopdict[loopid][period][day][t1:t2]\n",
    "            vol = vol + sum(loopvol)\n",
    "            n = n + np.count_nonzero(loopvol)\n",
    "    if n == 0:\n",
    "        #uncomment for the code below to check detailed id information identified with missing data\n",
    "        #print('loopid:', loopid, 'has identified with missing data when calculating weekly average at', period, 'period')\n",
    "        avg = 0\n",
    "    else:   \n",
    "        avg = round(vol/n, 3)  \n",
    "    #return the average traffic volume based on given daily and hourly bound\n",
    "    return(avg)\n",
    "\n",
    "def CaldailyAvg(loopdict, datetime, loopid, period, t1, t2, d1, d2):\n",
    "    DailyAvg = {}\n",
    "    for day in datetime:\n",
    "        # the bound defined for different days\n",
    "        if day.weekday() >= d1 and day.weekday() <= d2:\n",
    "            DailyAvg[day] = []\n",
    "            loopvol = loopdict[loopid][period][day][t1:t2]\n",
    "            vol = sum(loopvol)\n",
    "            n = len(np.nonzero(loopvol)[0])\n",
    "            if n == 0:\n",
    "                #uncomment for the code below to check detailed id information identified with missing data\n",
    "                #print('loopid:', loopid, ' has identified with missing data when calculating daily average at ', period, ' period')\n",
    "                avg = 0\n",
    "            else:\n",
    "                avg = round(vol/n, 3)\n",
    "\n",
    "            DailyAvg[day].append(round(vol,3))\n",
    "            DailyAvg[day].append(n)\n",
    "            DailyAvg[day].append(avg) \n",
    "    #return a list which contains the total loop vol, number of n calculated in the loops,\n",
    "    #and the calculated average \n",
    "    return(DailyAvg)\n",
    "\n",
    "# calculate hourly average of traffic volume\n",
    "def CalHourAvg(loopvoldict, d1, d2, direct, route):\n",
    "    loop_list = []\n",
    "    for lpid in list(loopvoldict.keys()):\n",
    "        if lpid[:3] in route and lpid[-1] in direct:\n",
    "            loop_list.append(lpid)\n",
    "\n",
    "    # create dict for hourly average calculation\n",
    "    avg_lp_hr = {} # dict for hourly average of each loop\n",
    "    avg_hr = {} # dict for hourly average based on all loops\n",
    "    periodlst = {}\n",
    "    for pd in loopvoldict[loop_list[0]]:\n",
    "        avg_lp_hr[pd] = {}\n",
    "        avg_hr[pd] = {}\n",
    "        periodlst[pd] = {}\n",
    "    #get hourly volume from the selected date\n",
    "    for pd in periodlst:\n",
    "        for lpid in loop_list: \n",
    "            daylst = list(loopvoldict[loop_list[0]][pd].keys())\n",
    "            periodlst[pd][lpid] = {}\n",
    "            for h in range(24):\n",
    "                periodlst[pd][lpid][h] = []\n",
    "                for d in daylst:\n",
    "                    if d.weekday()>= d1 and d.weekday()<=d2:\n",
    "                        periodlst[pd][lpid][h].append(round(loopvoldict[lpid][pd][d][h],3))\n",
    "\n",
    "    for pd in periodlst:\n",
    "        for lpid in loop_list:\n",
    "            avg_lp_hr[pd][lpid] = {}\n",
    "            avg_hr[pd] = {}\n",
    "            for h in range(24):\n",
    "                avg_lp_hr[pd][lpid][h] = []\n",
    "                avg_hr[pd][h] = []\n",
    "                sum_vol = round(sum(periodlst[pd][lpid][h]),3)\n",
    "                num = len(np.nonzero(periodlst[pd][lpid][h])[0])\n",
    "                # calculate the sum of hourly traffic volume for a specific loop\n",
    "                # calculate the total avaiable data count\n",
    "                avg_lp_hr[pd][lpid][h].append(sum_vol)\n",
    "                avg_lp_hr[pd][lpid][h].append(num)\n",
    "                if num == 0:\n",
    "                    avg_lp_hr[pd][lpid][h].append(0)\n",
    "                else:\n",
    "                    # calculate the daily average\n",
    "                    avg_lp_hr[pd][lpid][h].append(round(sum_vol/num, 3))\n",
    "    \n",
    "    for pd in periodlst:\n",
    "        for i in range(len(loop_list)):\n",
    "            for h in range(24):\n",
    "                if i == 0:\n",
    "                    avg_hr[pd][h] = list(avg_lp_hr[pd][loop_list[i]][h][:2])\n",
    "                else:\n",
    "                    avg_hr[pd][h][0] = avg_hr[pd][h][0] + avg_lp_hr[pd][loop_list[i]][h][0]\n",
    "                    avg_hr[pd][h][1] = avg_hr[pd][h][1] + avg_lp_hr[pd][loop_list[i]][h][1]\n",
    "    \n",
    "    for pd in periodlst:\n",
    "        for i in range(24):\n",
    "            avg = round(avg_hr[pd][i][0]/avg_hr[pd][i][1],3)\n",
    "            avg_hr[pd][i].append(avg)\n",
    "            \n",
    "    return(avg_lp_hr, avg_hr)\n",
    "\n",
    "# calculated the hourly average traffic volume based on different day of all available loops\n",
    "def getAvgHrbyDay(loopvoldict):\n",
    "    loop_list = list(loopvoldict.keys())\n",
    "    # create dict for hourly average calculation\n",
    "    hrplotlst = {} # dict for hourly average of each loop\n",
    "    periodlst = {}\n",
    "    for pd in loopvoldict[loop_list[0]]:\n",
    "        hrplotlst[pd] = {}    \n",
    "        periodlst[pd] = {}\n",
    "   \n",
    "    for pd in periodlst:\n",
    "        daylst = list(loopvoldict[loop_list[0]][pd].keys())\n",
    "        for d in daylst:\n",
    "            periodlst[pd][d] = {}\n",
    "            for i in range(24):\n",
    "                periodlst[pd][d][i] = []\n",
    "    for lpid in loop_list:\n",
    "        for pd in periodlst:\n",
    "            daylst = list(loopvoldict[lpid][pd].keys())\n",
    "            for d in daylst:\n",
    "                for i in range(24):\n",
    "                    periodlst[pd][d][i].append(loopvoldict[lpid][pd][d][i])\n",
    "                        \n",
    "    for pd in periodlst:\n",
    "        for d in list(periodlst[pd].keys()):\n",
    "            hrplotlst[pd][d] = []        \n",
    "            for i in range(24):\n",
    "                sum_vol = sum(periodlst[pd][d][i])\n",
    "                n = len(np.nonzero(periodlst[pd][d][i])[0])\n",
    "                if n == 0:\n",
    "                    avg = 0\n",
    "                else:\n",
    "                    avg = round(sum_vol/n, 3)\n",
    "                hrplotlst[pd][d].append(avg)\n",
    "    return(hrplotlst)   \n",
    "\n",
    "def CalallDayAvg(Avglst):\n",
    "    loop_list = list(Avglst.keys())\n",
    "    periodlst = list(Avglst[loop_list[0]].keys())\n",
    "    #create dict to store the data\n",
    "    allDayAvg = {}\n",
    "    for pd in periodlst:\n",
    "        allDayAvg[pd] = {}\n",
    "    for pd in periodlst:\n",
    "        daylst = list(Avglst[loop_list[0]][pd].keys())\n",
    "        for d in daylst:\n",
    "            allDayAvg[pd][d] = []\n",
    "    for i in range(len(loop_list)):            \n",
    "        for pd in periodlst:\n",
    "            daylst = list(Avglst[loop_list[i]][pd].keys())\n",
    "            for d in daylst:\n",
    "                if i == 0:\n",
    "                    allDayAvg[pd][d] = list(Avglst[loop_list[i]][pd][d])\n",
    "                else:\n",
    "                    allDayAvg[pd][d][0] = allDayAvg[pd][d][0]+Avglst[loop_list[i]][pd][d][0]\n",
    "                    allDayAvg[pd][d][1] = allDayAvg[pd][d][1]+Avglst[loop_list[i]][pd][d][1]\n",
    "    \n",
    "    for pd in periodlst:\n",
    "        daylst = list(allDayAvg[pd].keys())\n",
    "        for d in daylst:\n",
    "            if allDayAvg[pd][d][1] == 0:\n",
    "                allDayAvg[pd][d][2] = 0\n",
    "            else:\n",
    "                avg = round(allDayAvg[pd][d][0]/allDayAvg[pd][d][1],3)\n",
    "                allDayAvg[pd][d][2] = avg\n",
    "    return(allDayAvg)\n",
    "\n",
    "# plot data\n",
    "# plot data based on the calculated traffic volume \n",
    "# plot daily average traffic volume at each time period\n",
    "def plothr(legendlst, loopvoldict,figname):\n",
    "    figure(num=None, figsize=(6, 4), dpi=160, facecolor='w', edgecolor='k')\n",
    "    matplotlib.rcParams.update({'font.size': 11,})\n",
    "    plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    plotdata = getAvgHrbyDay(loopvoldict)\n",
    "    x = list(range(168))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.8, 0.8, 1, 1]) # main axes\n",
    "    #tide data so the day starts on Monday\n",
    "    y = {}\n",
    "    i = 0\n",
    "    for p in plotdata:\n",
    "        y[p] = []\n",
    "        i = i + 1\n",
    "        for d in plotdata[p]:\n",
    "            if d.weekday()>=5:\n",
    "                pass\n",
    "            else:\n",
    "                y[p].extend(plotdata[p][d])\n",
    "        for d in plotdata[p]:\n",
    "            if d.weekday()>=5:\n",
    "                y[p].extend(plotdata[p][d])\n",
    "        if i == 1:\n",
    "            ax.plot(x, y[p], 'r')\n",
    "        elif i == 2:\n",
    "            ax.plot(x, y[p], '--*b')\n",
    "        elif i == 3:\n",
    "            ax.plot(x, y[p], '--k')\n",
    "        else:\n",
    "            ax.plot(x, y[p])\n",
    "        \n",
    "    #ax.set_title('Hourly average traffic volume based on WSDOT loop data', fontsize=12)\n",
    "    ax.set_xlabel('Date', fontsize=14)\n",
    "    ax.set_xticks([0, 24, 48, 72, 96, 120, 144])\n",
    "    ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], fontsize=14)\n",
    "    ax.set_ylabel(\"Average traffic volume\", fontsize=14) \n",
    "\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.grid(which='minor', linestyle=':')\n",
    "    plt.legend(legendlst, loc='lower left', bbox_to_anchor=(1., 0.5), fontsize=13)\n",
    "    plt.savefig(figname, bbox_inches = 'tight', transparent=True, pad_inches=0) \n",
    "    plt.show()\n",
    "\n",
    "# plot hourly average traffic volume at each time period\n",
    "def hourlyplot(Avghourdicts, notes, legendlst, figname):\n",
    "    figure(num=None, figsize=(6, 4), dpi=160, facecolor='w', edgecolor='k')\n",
    "    matplotlib.rcParams.update({'font.size': 11,})\n",
    "    plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #create a dic to store the data\n",
    "    hourdic={}\n",
    "    for period in Avghourdicts:\n",
    "        hourdic[period] = []\n",
    "        x =  list(range(len(Avghourdicts[period])))\n",
    "    #create figure to plot the data\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.8, 0.8, 1, 1]) # main axes\n",
    "    \n",
    "    #get the average hourly data\n",
    "    #set up an index a to plot the volume in different time period seperately\n",
    "    a = 0\n",
    "    for pd in Avghourdicts:\n",
    "        a = a+1\n",
    "        for hr in Avghourdicts[pd]:\n",
    "            hourdic[pd].append(Avghourdicts[pd][hr][2])  \n",
    "        if a == 1:\n",
    "            ax.plot(x, hourdic[pd], 'r')\n",
    "        elif a == 2:\n",
    "            ax.plot(x, hourdic[pd],'--*b')\n",
    "        elif a == 3:\n",
    "            ax.plot(x, hourdic[pd],'-ok')\n",
    "        else:\n",
    "            ax.plot(x, hourdic[pd])\n",
    "\n",
    "    #ax.set_title('Average traffic volume based on loop data by hour' + notes, fontsize = 14)\n",
    "    ax.set_xlabel('Hour', fontsize = 14)\n",
    "    ax.set_ylabel(\"Traffic volume (vehicles)\", fontsize = 14) \n",
    "\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.grid(which='minor', linestyle=':')\n",
    "    plt.legend(legendlst, loc='lower left', bbox_to_anchor=(1., 0.5), fontsize=13)\n",
    "    plt.savefig(figname, bbox_inches = 'tight', transparent=True, pad_inches=0) \n",
    "    plt.show()\n",
    "\n",
    "# save data  \n",
    "# the data_dict should follow the format {period:traffic volume}\n",
    "# e.g., {'Before closure':{},'After closure':{}}\n",
    "def savedailydata(csvname, filepath, loopvoldict):\n",
    "    data_dict = getAvgHrbyDay(loopvoldict)\n",
    "    with open (filepath+csvname, 'w', newline='') as csv_file:\n",
    "        colnames = []\n",
    "        for period in data_dict:\n",
    "            colnames.append(period)\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=colnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        day_dict = {}\n",
    "        \n",
    "        for period in colnames:\n",
    "            day_dict[period] = {}\n",
    "            a=0\n",
    "            for day in data_dict[period]:\n",
    "                day_dict[period][a] = day\n",
    "                a = a+1\n",
    "            data_len = len(data_dict[period][day])\n",
    "        \n",
    "        for i in range(a):\n",
    "            for j in range(data_len):\n",
    "                row = {}\n",
    "                for k in colnames:\n",
    "                    row[k] = data_dict[k][day_dict[k][i]][j]\n",
    "                writer.writerow(row)       \n",
    "            \n",
    "def saveavghourlydata(csvname, filepath, data_dict):\n",
    "    with open(filepath+csvname, 'w',newline='') as csv_file:\n",
    "        colnames = []\n",
    "        for period in data_dict:\n",
    "            colnames.append(period)\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=colnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        hour = []\n",
    "        for h in data_dict[colnames[0]]:\n",
    "            hour.append(h)\n",
    "        \n",
    "        for h in hour:\n",
    "            row = {}\n",
    "            for k in colnames:\n",
    "                row[k] = data_dict[k][h][2]\n",
    "                \n",
    "            writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caution: there are other files detected except the zipped file in the given folder\n",
      "Warning: other files may cause error for other functions\n",
      "Caution: there are other files detected except the zipped file in the given folder\n",
      "Warning: other files may cause error for other functions\n"
     ]
    }
   ],
   "source": [
    "# run examples\n",
    "p1 = '../acbcao/'\n",
    "date1 = datetime(2019,1,5,0,0)\n",
    "date2 = datetime(2019,3,22,0,0)\n",
    "raw_data_process(p1, date1, date2)\n",
    "\n",
    "p2 = '../atbt/'\n",
    "date1 = datetime(2019,11,2,0,0)\n",
    "date2 = datetime(2019,11,22,0,0)\n",
    "raw_data_process(p2, date1, date2)\n",
    "\n",
    "# check if data is available based on the time of interest\n",
    "# and delete all the missing data\n",
    "#bc period\n",
    "bc1 = datetime(2019, 1, 5, 0, 0)\n",
    "bc2 = datetime(2019, 1, 11, 0, 0)\n",
    "#ac period\n",
    "ac1 = datetime(2019, 1, 12, 0, 0)\n",
    "ac2 = datetime(2019, 1, 18, 0, 0)\n",
    "#ao2 period\n",
    "ao21 = datetime(2019, 3, 16, 0, 0)\n",
    "ao22 = datetime(2019, 3, 22, 0, 0)\n",
    "#bt\n",
    "bt1 = datetime(2019,11,2,0,0)\n",
    "bt2 = datetime(2019,11,8,0,0)\n",
    "#at1\n",
    "at11 = datetime(2019,11,9,0,0)\n",
    "at12 = datetime(2019,11,15,0,0)\n",
    "#at2\n",
    "at21 = datetime(2019,11,16,0,0)\n",
    "at22 = datetime(2019,11,22,0,0)\n",
    "\n",
    "acbcao = ['BC','AC','AO2']\n",
    "atbt = ['BT','AT1','AT2']\n",
    "\n",
    "# for acbcao\n",
    "# get current available .xlsx file      \n",
    "loop_vol1 = makeloopvol(acbcao, p1)\n",
    "acbcao_bond = [bc1, bc2, ac1, ac2, ao21, ao22]\n",
    "\n",
    "# for atbt\n",
    "loop_vol2 = makeloopvol(atbt, p2)\n",
    "atbt_bond = [bt1, bt2, at11, at12, at21, at22]\n",
    "\n",
    "#acbcao\n",
    "loop_vol1 = excel_processing(p1, acbcao, acbcao_bond, loop_vol1)\n",
    "loc1 = get_loop_location(loop_vol1, p1)\n",
    "#atbt\n",
    "loop_vol2 = excel_processing(p2, atbt, atbt_bond, loop_vol2)\n",
    "loc2 = get_loop_location(loop_vol2, p2)\n",
    "\n",
    "# Daily\n",
    "# weekday\n",
    "WeekAvg, DayAvg = CalVol(loop_vol1, 0, 24, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_kd, DayAvg_kd = CalVol(loop_vol1, 0, 24, 5, 6)\n",
    "\n",
    "# morning peak 6:00 am - 10:00 am \n",
    "# weekday\n",
    "WeekAvg_mor, DayAvg_mor = CalVol(loop_vol1, 6, 11, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_mor_kd, DayAvg_mor_kd = CalVol(loop_vol1, 6, 11, 5, 6)\n",
    "\n",
    "# evening peak 3:00 pm - 7:00 pm (15:00 - 19:00)\n",
    "# weekday\n",
    "WeekAvg_eve, DayAvg_eve = CalVol(loop_vol1, 15, 20, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_eve_kd, DayAvg_eve_kd = CalVol(loop_vol1, 15, 20, 5, 6)\n",
    "\n",
    "#calculate average hourly traffic volume\n",
    "AvgLPhr,AvgHr = CalHourAvg(loop_vol1, 0, 6, ['N','S'], ['005','099'])\n",
    "AvgLPhr_wd_acbc,AvgHr_wd_acbc = CalHourAvg(loop_vol1, 1, 3, ['N','S'], ['005','099'])\n",
    "AvgLPhr_wk_acbc,AvgHr_wk_acbc = CalHourAvg(loop_vol1, 5, 6, ['N','S'], ['005','099'])\n",
    "AvgLPhr_wd_atbt,AvgHr_wd_atbt = CalHourAvg(loop_vol2, 1, 3, ['N','S'], ['005','099'])\n",
    "AvgLPhr_wk_atbt,AvgHr_wk_atbt = CalHourAvg(loop_vol2, 5, 6, ['N','S'], ['005','099'])\n",
    "\n",
    "# daily avg based on all loops\n",
    "alldayAvg = CalallDayAvg(DayAvg)\n",
    "alldayAvg_mor = CalallDayAvg(DayAvg_mor)\n",
    "alldayAvg_eve = CalallDayAvg(DayAvg_eve)\n",
    "\n",
    "b# make legend for AC period, BC period and AO period\n",
    "lgacbcao = ['Before closure (1/5 - 1/11)','After closure (1/12 - 1/18)','After opening 2 (3/16-3/22)']\n",
    "# make legend for AT period, BT period\n",
    "lgatbt = ['Before tolling (11/2 - 11/8)','After tolling 1(11/9 - 11/15)','After tolling 2(11/16-11/22)']\n",
    "\n",
    "# plot hourly average\n",
    "p = 'G:/My Drive/2020/FHWA/FHWA_2020_plot/Loop/'\n",
    "plothr(lgacbcao, loop_vol1, p+'acbc_daily_avg.jpg')\n",
    "plothr(lgatbt, loop_vol2, p+'atbt_daily_avg.jpg')\n",
    "#tidedictandplot(AvgHr, '')\n",
    "hourlyplot(AvgHr_wd_atbt, ' (weekday)', lgatbt, p+'atbt_hr_avg_wd.jpg')\n",
    "hourlyplot(AvgHr_wk_atbt, ' (weekend)', lgatbt, p+'atbt_hr_avg_wk.jpg')\n",
    "hourlyplot(AvgHr_wd_acbc, ' (weekday)', lgacbcao, p+'acbc_hr_avg_wd.jpg')\n",
    "hourlyplot(AvgHr_wk_acbc, ' (weekend)', lgacbcao, p+'acbc_hr_avg_wk.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for plot\n",
    "p = 'G:/My Drive/2020/FHWA/FHWA_2020_plot/Loop/'\n",
    "savedailydata('loop_acbc_day.csv', p, loop_vol1)\n",
    "savedailydata('loop_atbt_day.csv', p, loop_vol2)\n",
    "saveavghourlydata('loop_acbc_hr_wd.csv', p, AvgHr_wd_acbc)\n",
    "saveavghourlydata('loop_acbc_hr_wk.csv', p, AvgHr_wk_acbc)\n",
    "saveavghourlydata('loop_atbt_hr_wd.csv', p, AvgHr_wd_atbt)\n",
    "saveavghourlydata('loop_atbt_hr_wk.csv', p, AvgHr_wk_atbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "def make_row(bc, ac, ao2, sesid, loc):\n",
    "    row = {}\n",
    "    row['sensys id'] = sesid\n",
    "    row['bc_avg'] = bc\n",
    "    row['ac_avg'] = ac\n",
    "    row['ao1_avg'] = None\n",
    "    row['ao2_avg'] = ao2\n",
    "    row['bcac_vol'] = row['ac_avg'] - row['bc_avg']\n",
    "    row['bcao1_vol'] = None\n",
    "    row['acao1_vol'] = None\n",
    "    row['ao1ao2_vol'] = None\n",
    "    row['bcao1_per'] = None\n",
    "    row['acao1_per'] = None\n",
    "    row['ao1ao2_per'] = None\n",
    "    row['lat'] = loc[sesid][0]\n",
    "    row['lon'] = loc[sesid][1]\n",
    "    row['direction'] = sesid[-1]+'BT'\n",
    "    if ao2 == 0:\n",
    "        row['bcao2_vol'] = None\n",
    "        row['acao2_vol'] = None\n",
    "        row['bcao2_per'] = None\n",
    "        row['acao2_per'] = None\n",
    "    else:\n",
    "        if bc == 0:\n",
    "            row['bcao2_per'] = 0\n",
    "            row['bcac_per'] = 0\n",
    "        if ac == 0:\n",
    "            row['acao2_per'] =0\n",
    "        else:            \n",
    "            row['bcao2_vol'] = row['ao2_avg'] - row['bc_avg']\n",
    "            row['acao2_vol'] = row['ao2_avg'] - row['ac_avg']\n",
    "            row['bcao2_per'] = round(row['bcao2_vol']/row['bc_avg'],5)\n",
    "            row['acao2_per'] = round(row['acao2_vol']/row['ac_avg'],5)\n",
    "            row['bcac_per'] = round(row['bcac_vol']/row['bc_avg'],5)\n",
    "    return(row)\n",
    "\n",
    "def write_csv(csvname, Avgvollst, loclst):\n",
    "    with open(csvname, 'w', newline='') as csvfile:\n",
    "        colnames = ['sensys id', 'bc_avg','ac_avg','ao1_avg','ao2_avg','bcac_per','bcao1_per','bcao2_per','acao1_per','acao2_per','ao1ao2_per','bcac_vol','bcao1_vol','bcao2_vol','acao1_vol','acao2_vol','ao1ao2_vol','lat','lon','direction']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=colnames)\n",
    "        writer.writeheader()\n",
    "        for loopid in Avgvollst:\n",
    "            bc = Avgvollst[loopid]['BC']\n",
    "            ac = Avgvollst[loopid]['AC']\n",
    "            ao2 = Avgvollst[loopid]['AO2']\n",
    "            row = make_row(bc, ac, ao2, loopid, loclst)\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(p+'lp_weekday_acbc_formap.csv', WeekAvg,  get_loop_location(loop_vol1, p1))\n",
    "write_csv(p+'lp_weekend_acbc_formap.csv', WeekAvg_kd, get_loop_location(loop_vol1, p1))\n",
    "write_csv(p+'lp_mor_weekday_acbc_formap.csv',WeekAvg_mor, get_loop_location(loop_vol1, p1))\n",
    "write_csv(p+'lp_mor_weekend_acbc_formap.csv',WeekAvg_mor_kd, get_loop_location(loop_vol1, p1))\n",
    "write_csv(p+'lp_eve_weekday_acbc_formap.csv',WeekAvg_eve, get_loop_location(loop_vol1, p1))\n",
    "write_csv(p+'lp_eve_weekend_acbc_formap.csv',WeekAvg_eve_kd, get_loop_location(loop_vol1, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_row(bt, at1, at2, sesid, loc):\n",
    "    row = {}\n",
    "    row['sensys id'] = sesid\n",
    "    row['bt_avg'] = bt\n",
    "    row['at1_avg'] = at1\n",
    "    row['at2_avg'] = at2\n",
    "    row['btat1_vol'] = row['at1_avg'] - row['bt_avg']\n",
    "    row['btat2_vol'] = row['at2_avg'] - row['bt_avg']\n",
    "    row['at1at2_vol'] = row['at2_avg'] - row['at1_avg']\n",
    "    row['btat1_per'] = round(row['btat1_vol']/row['bt_avg'],5)\n",
    "    row['btat2_per'] = round(row['btat2_vol']/row['bt_avg'],5)\n",
    "    row['at1at2_per'] = round(row['at1at2_vol'] /row['at1_avg'],5)\n",
    "    row['lat'] = loc[sesid][0]\n",
    "    row['lon'] = loc[sesid][1]\n",
    "    row['direction'] = sesid[-3:]\n",
    "    return(row)\n",
    "\n",
    "def write_csv(csvname, Avgvollst, loclst):\n",
    "    with open(csvname, 'w', newline='') as csvfile:\n",
    "        colnames = ['sensys id', 'bt_avg','at1_avg','at2_avg','btat1_vol','btat2_vol','at1at2_vol','btat1_per','btat2_per','at1at2_per','lat','lon','direction']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=colnames)\n",
    "        writer.writeheader()\n",
    "        for loopid in Avgvollst:\n",
    "            bt = Avgvollst[loopid]['BT']\n",
    "            at1 = Avgvollst[loopid]['AT1']\n",
    "            at2 = Avgvollst[loopid]['AT2']\n",
    "            row = make_row(bt, at1, at2, loopid, loclst)\n",
    "            writer.writerow(row)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily\n",
    "# weekday\n",
    "WeekAvg, DayAvg = CalVol(loop_vol2, 0, 24, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_kd, DayAvg_kd = CalVol(loop_vol2, 0, 24, 5, 6)\n",
    "\n",
    "# morning peak 6:00 am - 10:00 am \n",
    "# weekday\n",
    "WeekAvg_mor, DayAvg_mor = CalVol(loop_vol2, 6, 11, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_mor_kd, DayAvg_mor_kd = CalVol(loop_vol2, 6, 11, 5, 6)\n",
    "\n",
    "# evening peak 3:00 pm - 7:00 pm (15:00 - 19:00)\n",
    "# weekday\n",
    "WeekAvg_eve, DayAvg_eve = CalVol(loop_vol2, 14, 20, 1, 3)\n",
    "# weekend\n",
    "WeekAvg_eve_kd, DayAvg_eve_kd = CalVol(loop_vol2, 14, 20, 5, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:/My Drive/2020/FHWA/FHWA_2020_plot/Loop/'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(p+'lp_weekday_atbt_formap.csv', WeekAvg,  get_loop_location(loop_vol2, p2))\n",
    "write_csv(p+'lp_weekend_atbt_formap.csv', WeekAvg_kd, get_loop_location(loop_vol2, p2))\n",
    "write_csv(p+'lp_mor_weekday_atbt_formap.csv',WeekAvg_mor, get_loop_location(loop_vol2, p2))\n",
    "write_csv(p+'lp_mor_weekend_atbt_formap.csv',WeekAvg_mor_kd, get_loop_location(loop_vol2, p2))\n",
    "write_csv(p+'lp_eve_weekday_atbt_formap.csv',WeekAvg_eve, get_loop_location(loop_vol1, p2))\n",
    "write_csv(p+'lp_eve_weekend_atbt_formap.csv',WeekAvg_eve_kd, get_loop_location(loop_vol2, p2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
